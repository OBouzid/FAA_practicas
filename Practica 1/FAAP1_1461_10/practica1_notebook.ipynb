{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos las librerias tanto del sklearn como las nuestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Clasificador\n",
    "import EstrategiaParticionado\n",
    "from Datos import Datos\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos un programa de prueba para mostrar las comparaciones de las predicciones con nuestra implementacion del algoritmo y la de SKLEARN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion simple\n",
    "\n",
    "Primero, ejecutaremos nuestra implementación con validación simple, sin la correción de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.303664921466\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_t, error_std_sin = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecutamos sklearn con validación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286458333333\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1]\n",
    "clf = MultinomialNB(alpha=0)\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_sin_t = 1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo ejecutaremos con la correción de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.294502617801\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_t, error_std_con = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.296875\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_con_t = 1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente paso, ejecutamos lo anterior con el conjunto de datos 'german.data' y cambiando la variable 'clf' para que ejecute Naive Bayes con GaussianNB, ya que el conjunto 'german.data' contiene valores continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285714285714\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/german.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1]\n",
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_sin_g =  1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.271929824561\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2975\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_con_g =  1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)\n",
    "\n",
    "\n",
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (error_media_sin_t)\n",
    "salida += \"<td>%f</td></tr>\" % (error_sk_sin_t)\n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (error_media_con_t)\n",
    "salida += \"<td>%f</td></tr></table>\" % (error_sk_con_t)\n",
    "\n",
    "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida2 += \"<td>%f</td>\" % (error_media_sin_g)\n",
    "salida2 += \"<td>%f</td></tr>\" % (error_sk_sin_g)\n",
    "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
    "salida2 += \"<td>%f</td>\" % (error_media_con_g)\n",
    "salida2 += \"<td>%f</td></tr></table>\" % (error_sk_con_g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUMEN DE DATOS\n",
    "\n",
    "Vamos a representar mediante tablas los distintas tasas de error obtenidas\n",
    "##### Tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.303665</td><td>0.286458</td></tr><tr><td>NB con Laplace</td><td>0.294503</td><td>0.296875</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar los datos son muy parejo, por tanto no se podria considerar la implementacion mejor que la oficial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.285714</td><td>0.230000</td></tr><tr><td>NB con Laplace</td><td>0.271930</td><td>0.297500</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hay mas diferencia entre nuestra implementacion y la de Sklearn, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son.\n",
    "\n",
    "Hasta ahora, hemos ejecutado la validación simple. A continuación ejecutaremos los mismos ejemplos con validación cruzada.\n",
    "\n",
    "## Validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.298947368421 0.0309409230667\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_t, error_std_sin_t = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_t, error_std_sin_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335916531018 0.0867089672528\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "Y = dataset.datos[:, -1]\n",
    "clf = MultinomialNB(0)\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_sin_t = 1 - score.mean()\n",
    "error_std_sk_sin_t = score.std()\n",
    "print error_media_sk_sin_t, error_std_sk_sin_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.300526315789 0.0398716778242\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_t, error_std_con_t = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_t, error_std_con_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.334874864352 0.087666994993\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(1)\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_con_t = 1 - score.mean()\n",
    "error_std_sk_con_t = score.std()\n",
    "print error_media_sk_con_t, error_std_sk_con_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, ejecutamos lo anterior con el conjuento de datos 'german.data' y GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.233 0.041\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/german.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada() #por defecto, 10\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_g, error_std_sin_g = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_g, error_std_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286 0.0341174442185\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "Y = dataset.datos[:, -1]\n",
    "clf = GaussianNB()\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_sin_g = 1 - score.mean()\n",
    "error_std_sk_sin_g = score.std()\n",
    "print error_media_sk_sin_g, error_std_sk_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2315 0.0394049489278\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_g, error_std_con_g = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_g, error_std_con_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286 0.0341174442185\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "error_media_sk_con_g = 1 - score.mean()\n",
    "error_std_sk_con_g = score.std()\n",
    "print error_media_sk_con_g, error_std_sk_con_g\n",
    "\n",
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%.4f ± %.3f</td>\" % (error_media_sin_t,error_std_sin_t)\n",
    "salida += \"<td>%.4f ± %.3f</td></tr>\" % (error_media_sk_sin_t,error_std_sk_sin_t)\n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%.4f ± %.3f</td>\" % (error_media_con_t,error_std_con_t)\n",
    "salida += \"<td>%.4f ± %.3f</td></tr></table>\" % (error_media_sk_con_t,error_std_sk_con_t)\n",
    "\n",
    "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida2 += \"<td>%.4f ± %.3f</td>\" % (error_media_sin_g,error_std_sin_g)\n",
    "salida2 += \"<td>%.4f ± %.3f</td></tr>\" % (error_media_sk_sin_g,error_std_sk_sin_g)\n",
    "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
    "salida2 += \"<td>%.4f ± %.3f</td>\" % (error_media_con_g,error_std_con_g)\n",
    "salida2 += \"<td>%.4f ± %.3f</td></tr></table>\" % (error_media_sk_con_g,error_std_sk_con_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUMEN DE DATOS\n",
    "\n",
    "Vamos a representar mediante tablas los distintas tasas medias de error y las desviaciones obtenidas.\n",
    "\n",
    "##### Tic-tac-toe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.2989 ± 0.031</td><td>0.3359 ± 0.087</td></tr><tr><td>NB con Laplace</td><td>0.3005 ± 0.040</td><td>0.3349 ± 0.088</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados como en el caso anterior la diferencia es de un 3% dependiendo de la ejecucion, por lo tanto no se puede decir que haya una mejor que otra.\n",
    "\n",
    "La desviación estandar, en nuestra implementación, mejora entorno a un 5% la de sklearn. Estos nos puede decir que nuestra implementación puede ser mejor que la de sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.2330 ± 0.041</td><td>0.2860 ± 0.034</td></tr><tr><td>NB con Laplace</td><td>0.2315 ± 0.039</td><td>0.2860 ± 0.034</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se puede observar que el porcentaje de error en nuestra implementación es más bajo. En torno al 8%. Como hemos comentado anteriormente, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son.\n",
    "\n",
    "En este caso las desviaciones estandar son más bajas con la implementación de sklearn. Aproximadamente un 1%. Creemos que no se puede sacar una conclusión con un desvío de un 1%, esto puede ser a que los datos se calculan siguiendo una distribuición normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### NOTA Estas mediciones pueden variar en las siguientes ejecuciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
