{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practica 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluimos las librerias tanto del sklearn como las nuestras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Clasificador\n",
    "import EstrategiaParticionado\n",
    "from Datos import Datos\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora haremos un programa de prueba para mostrar las comparaciones de las predicciones con nuestra implementacion del algoritmo y la de SKLEARN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validacion simple\n",
    "\n",
    "Primero, ejecutaremos nuestra implementación con validación simple, sin la correción de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.267015706806\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_t, error_std_sin = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ejecutamos sklearn con validación simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2890625\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1]\n",
    "clf = MultinomialNB(alpha=0)\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_sin_t = 1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo ejecutaremos con la correción de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.261780104712\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_t, error_std_con = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.276041666667\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(alpha=1)\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_con_t = 1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente paso, ejecutamos lo anterior con el conjunto de datos 'german.data' y cambiando la variable 'clf' para que ejecute Naive Bayes con GaussianNB, ya que el conjunto 'german.data' contiene valores continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.245614035088\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/german.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media_sin_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_sin_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
    "Y = dataset.datos[:,-1]\n",
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_sin_g =  1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255639097744\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media_con_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media_con_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2925\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
    "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
    "error_sk_con_g =  1 - accuracy_score(y_test, predicciones)\n",
    "print 1 - accuracy_score(y_test, predicciones)\n",
    "\n",
    "\n",
    "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (error_media_sin_t)\n",
    "salida += \"<td>%f</td></tr>\" % (error_sk_sin_t)\n",
    "salida += \"<tr><td>NB con Laplace</td>\"\n",
    "salida += \"<td>%f</td>\" % (error_media_con_t)\n",
    "salida += \"<td>%f</td></tr></table>\" % (error_sk_con_t)\n",
    "\n",
    "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
    "salida2 += \"<td>%f</td>\" % (error_media_sin_g)\n",
    "salida2 += \"<td>%f</td></tr>\" % (error_sk_sin_g)\n",
    "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
    "salida2 += \"<td>%f</td>\" % (error_media_con_g)\n",
    "salida2 += \"<td>%f</td></tr></table>\" % (error_sk_con_g)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESUMEN DE DATOS\n",
    "\n",
    "Vamos a representar mediante tablas los distintas tasas de error obtenidas\n",
    "##### Tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.267016</td><td>0.289062</td></tr><tr><td>NB con Laplace</td><td>0.261780</td><td>0.276042</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar los datos son muy parejo, por tanto no se podria considerar la implementacion mejor que la oficial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.245614</td><td>0.300000</td></tr><tr><td>NB con Laplace</td><td>0.255639</td><td>0.292500</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(salida2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso hay mas diferencia entre nuestra implementacion y la de Sklearn, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son.\n",
    "\n",
    "Hasta ahora, hemos ejecutado la validación simple. A continuación ejecutaremos los mismos ejemplos con validación cruzada.\n",
    "\n",
    "## Validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.291578947368\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada()\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335916531018 0.0867089672528\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "Y = dataset.datos[:, -1]\n",
    "clf = MultinomialNB(0)\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "print 1 - score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.293157894737\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.334874864352 0.087666994993\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB(1)\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "print 1 - score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, ejecutamos lo anterior con el conjuento de datos 'german.data' y GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.224\n"
     ]
    }
   ],
   "source": [
    "dataset = Datos('./ConjuntosDatos/german.data')\n",
    "estrategia = EstrategiaParticionado.ValidacionCruzada() #por defecto, 10\n",
    "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
    "error_media, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286 0.0341174442185\n"
     ]
    }
   ],
   "source": [
    "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
    "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
    "Y = dataset.datos[:, -1]\n",
    "clf = GaussianNB()\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "print 1 - score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.223333333333\n"
     ]
    }
   ],
   "source": [
    "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
    "error_media, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
    "print error_media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286 0.0341174442185\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "score = cross_val_score(clf, X, Y, cv=10)\n",
    "print 1 - score.mean(), score.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESUMEN DE DATOS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
