{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Practica 1 "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Incluimos las librerias tanto del sklearn como las nuestras."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import Clasificador\n",
      "import EstrategiaParticionado\n",
      "from Datos import Datos\n",
      "from sklearn import preprocessing\n",
      "from sklearn.model_selection import cross_val_score\n",
      "from sklearn.naive_bayes import GaussianNB\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.metrics import accuracy_score\n",
      "from IPython.display import HTML, display"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ahora haremos un programa de prueba para mostrar las comparaciones de las predicciones con nuestra implementacion del algoritmo y la de SKLEARN."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Validacion simple\n",
      "\n",
      "Primero, ejecutaremos nuestra implementaci\u00f3n con validaci\u00f3n simple, sin la correci\u00f3n de Laplace."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
      "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
      "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
      "error_media_sin_t, error_std_sin = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_sin_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.295811518325\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ahora ejecutamos sklearn con validaci\u00f3n simple."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
      "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
      "Y = dataset.datos[:,-1]\n",
      "clf = MultinomialNB(alpha=0)\n",
      "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
      "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
      "error_sk_sin_t = 1 - accuracy_score(y_test, predicciones)\n",
      "print 1 - accuracy_score(y_test, predicciones)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.2890625\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/ricar/.local/lib/python2.7/site-packages/sklearn/naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
        "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ahora lo ejecutaremos con la correci\u00f3n de Laplace."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
      "error_media_con_t, error_std_con = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_con_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.297120418848\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = MultinomialNB(alpha=1)\n",
      "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
      "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
      "error_sk_con_t = 1 - accuracy_score(y_test, predicciones)\n",
      "print 1 - accuracy_score(y_test, predicciones)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.299479166667\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En el siguiente paso, ejecutamos lo anterior con el conjunto de datos 'german.data' y cambiando la variable 'clf' para que ejecute Naive Bayes con GaussianNB, ya que el conjunto 'german.data' contiene valores continuos."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = Datos('./ConjuntosDatos/german.data')\n",
      "estrategia = EstrategiaParticionado.ValidacionSimple()\n",
      "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
      "error_media_sin_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_sin_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.203007518797\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1],sparse=False)\n",
      "X = encAtributos.fit_transform(dataset.datos[:,:-1])\n",
      "Y = dataset.datos[:,-1]\n",
      "clf = GaussianNB()\n",
      "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
      "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
      "error_sk_sin_g =  1 - accuracy_score(y_test, predicciones)\n",
      "print 1 - accuracy_score(y_test, predicciones)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.29\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
      "error_media_con_g, error_std = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_con_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.213032581454\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = GaussianNB()\n",
      "x_train, x_test, y_train,y_test = train_test_split(X,Y,test_size=0.4)\n",
      "predicciones=clf.fit(x_train,y_train).predict(x_test)\n",
      "error_sk_con_g =  1 - accuracy_score(y_test, predicciones)\n",
      "print 1 - accuracy_score(y_test, predicciones)\n",
      "\n",
      "\n",
      "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
      "salida += \"<td>%f</td>\" % (error_media_sin_t)\n",
      "salida += \"<td>%f</td></tr>\" % (error_sk_sin_t)\n",
      "salida += \"<tr><td>NB con Laplace</td>\"\n",
      "salida += \"<td>%f</td>\" % (error_media_con_t)\n",
      "salida += \"<td>%f</td></tr></table>\" % (error_sk_con_t)\n",
      "\n",
      "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
      "salida2 += \"<td>%f</td>\" % (error_media_sin_g)\n",
      "salida2 += \"<td>%f</td></tr>\" % (error_sk_sin_g)\n",
      "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
      "salida2 += \"<td>%f</td>\" % (error_media_con_g)\n",
      "salida2 += \"<td>%f</td></tr></table>\" % (error_sk_con_g)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.3225\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### RESUMEN DE DATOS\n",
      "\n",
      "Vamos a representar mediante tablas los distintas tasas de error obtenidas\n",
      "##### Tic-tac-toe"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(HTML(salida))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.267016</td><td>0.289062</td></tr><tr><td>NB con Laplace</td><td>0.261780</td><td>0.276042</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML object>"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Como se puede observar los datos son muy parejo, por tanto no se podria considerar la implementacion mejor que la oficial"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### German\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "display(HTML(salida2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.245614</td><td>0.300000</td></tr><tr><td>NB con Laplace</td><td>0.255639</td><td>0.292500</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML object>"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este caso hay mas diferencia entre nuestra implementacion y la de Sklearn, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son.\n",
      "\n",
      "Hasta ahora, hemos ejecutado la validaci\u00f3n simple. A continuaci\u00f3n ejecutaremos los mismos ejemplos con validaci\u00f3n cruzada.\n",
      "\n",
      "## Validacion cruzada"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = Datos('./ConjuntosDatos/tic-tac-toe.data')\n",
      "estrategia = EstrategiaParticionado.ValidacionCruzada()\n",
      "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
      "error_media_sin_t, error_std_sin_t = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_sin_t, error_std_sin_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.292631578947 0.0348483060153\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
      "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
      "Y = dataset.datos[:, -1]\n",
      "clf = MultinomialNB(0)\n",
      "score = cross_val_score(clf, X, Y, cv=10)\n",
      "error_media_sk_sin_t = 1 - score.mean()\n",
      "error_std_sk_sin_t = score.std()\n",
      "print error_media_sk_sin_t, error_std_sk_sin_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.335916531018 0.0867089672528\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
      "error_media_con_t, error_std_con_t = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_con_t, error_std_con_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.292105263158 0.0359863008715\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = MultinomialNB(1)\n",
      "score = cross_val_score(clf, X, Y, cv=10)\n",
      "error_media_sk_con_t = 1 - score.mean()\n",
      "error_std_sk_con_t = score.std()\n",
      "print error_media_sk_con_t, error_std_sk_con_t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.334874864352 0.087666994993\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Por \u00faltimo, ejecutamos lo anterior con el conjuento de datos 'german.data' y GaussianNB."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dataset = Datos('./ConjuntosDatos/german.data')\n",
      "estrategia = EstrategiaParticionado.ValidacionCruzada() #por defecto, 10\n",
      "clasificador = Clasificador.ClasificadorNaiveBayes()\n",
      "error_media_sin_g, error_std_sin_g = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_sin_g, error_std_sin_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.23 0.0392428337407\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "encAtributos = preprocessing.OneHotEncoder(categorical_features=dataset.nominalAtributos[:-1], sparse=False)\n",
      "X = encAtributos.fit_transform(dataset.datos[:, :-1])\n",
      "Y = dataset.datos[:, -1]\n",
      "clf = GaussianNB()\n",
      "score = cross_val_score(clf, X, Y, cv=10)\n",
      "error_media_sk_sin_g = 1 - score.mean()\n",
      "error_std_sk_sin_g = score.std()\n",
      "print error_media_sk_sin_g, error_std_sk_sin_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.286 0.0341174442185\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clasificador = Clasificador.ClasificadorNaiveBayes(laplace=True)\n",
      "error_media_con_g, error_std_con_g = clasificador.validacion(estrategia, dataset, clasificador)\n",
      "print error_media_con_g, error_std_con_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.23 0.0444971909226\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf = GaussianNB()\n",
      "score = cross_val_score(clf, X, Y, cv=10)\n",
      "error_media_sk_con_g = 1 - score.mean()\n",
      "error_std_sk_con_g = score.std()\n",
      "print error_media_sk_con_g, error_std_sk_con_g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.286 0.0341174442185\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### RESUMEN DE DATOS\n",
      "\n",
      "Vamos a representar mediante tablas los distintas tasas medias de error y las desviaciones obtenidas.\n",
      "\n",
      "##### Tic-tac-toe\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Medias de errores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
      "salida += \"<td>%f</td>\" % (error_media_sin_t)\n",
      "salida += \"<td>%f</td></tr>\" % (error_sk_sin_t)\n",
      "salida += \"<tr><td>NB con Laplace</td>\"\n",
      "salida += \"<td>%f</td>\" % (error_media_con_t)\n",
      "salida += \"<td>%f</td></tr></table>\" % (error_sk_con_t)\n",
      "\n",
      "display(HTML(salida))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.292632</td><td>0.289062</td></tr><tr><td>NB con Laplace</td><td>0.292105</td><td>0.299479</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x7f0987f39610>"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Los resultados entre las dos implementaciones son muy parejas, por lo tanto no se puede decir que haya una mejor que otra."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Desviaciones estandar"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salida = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
      "salida += \"<td>%f</td>\" % (error_std_sin_t)\n",
      "salida += \"<td>%f</td></tr>\" % (error_std_sk_sin_t)\n",
      "salida += \"<tr><td>NB con Laplace</td>\"\n",
      "salida += \"<td>%f</td>\" % (error_std_con_t)\n",
      "salida += \"<td>%f</td></tr></table>\" % (error_std_sk_con_t)\n",
      "\n",
      "display(HTML(salida))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.034848</td><td>0.086709</td></tr><tr><td>NB con Laplace</td><td>0.035986</td><td>0.087667</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x7f0987f396d0>"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "La desviaci\u00f3n estandar, en nuestra implementaci\u00f3n, mejora entorno a un 5% la de sklearn. Estos nos puede decir que nuestra implementaci\u00f3n puede ser mejor que la de sklearn."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##### German"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Medias de errores"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
      "salida2 += \"<td>%f</td>\" % (error_media_sin_g)\n",
      "salida2 += \"<td>%f</td></tr>\" % (error_sk_sin_g)\n",
      "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
      "salida2 += \"<td>%f</td>\" % (error_media_con_g)\n",
      "salida2 += \"<td>%f</td></tr></table>\" % (error_sk_con_g)\n",
      "\n",
      "display(HTML(salida2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.230000</td><td>0.290000</td></tr><tr><td>NB con Laplace</td><td>0.230000</td><td>0.322500</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x7f0987f39510>"
       ]
      }
     ],
     "prompt_number": 56
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este caso se puede observar que el porcentaje de error en nuestra implementaci\u00f3n es m\u00e1s bajo. En torno al 8%. Como hemos comentado anteriormente, esto se puede deber a que GaussianNB trata todos los datos como si siguieran una distribuccion normal y el nuestro distingue entre datos discretos y los que no lo son"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Desviaciones estandar"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "salida2 = \"<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td>\"\n",
      "salida2 += \"<td>%f</td>\" % (error_std_sin_g)\n",
      "salida2 += \"<td>%f</td></tr>\" % (error_std_sk_sin_g)\n",
      "salida2 += \"<tr><td>NB con Laplace</td>\"\n",
      "salida2 += \"<td>%f</td>\" % (error_std_con_g)\n",
      "salida2 += \"<td>%f</td></tr></table>\" % (error_std_sk_con_g)\n",
      "\n",
      "display(HTML(salida2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<table><tr><th>Clasificador</th><th>Nuestro</th><th>Sklearn</th></tr><tr><td>NB sin Laplace</td><td>0.039243</td><td>0.034117</td></tr><tr><td>NB con Laplace</td><td>0.044497</td><td>0.034117</td></tr></table>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.HTML at 0x7f0987f39f90>"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "En este caso las desviaciones estandar son m\u00e1s bajas con la implementaci\u00f3n de sklearn. Aproximadamente un 1%. Creemos que no se puede sacar una conclusi\u00f3n con un desv\u00edo de un 1%."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "NOTA Estas mediciones pueden variar en las siguientes ejecuciones."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}